# image_recognition/ocr_processor.py
"""
OCR æ¨¡çµ„ - ç”¨æ–¼å°‡èŠå¤©æˆªåœ–è½‰æˆæ–‡å­—è³‡æ–™
æ”¯æ´ä¸­è‹±æ··åˆè¾¨è­˜ï¼ŒåŒ…å«åŸºæœ¬å‰è™•ç†èˆ‡éŒ¯èª¤è™•ç†
"""

import pytesseract
from PIL import Image, ImageOps, ImageFilter
import cv2
import numpy as np
import os


def preprocess_image(image_path: str, save_debug: bool = True) -> np.ndarray:
    """
    è®€å–åœ–ç‰‡ä¸¦é€²è¡Œå‰è™•ç†ï¼Œæå‡ OCR æº–ç¢ºç‡ã€‚
    è‹¥ save_debug=Trueï¼Œæœƒå°‡æ¯å€‹æ­¥é©Ÿçš„åœ–ç‰‡å„²å­˜åœ¨ ./debug_images/ æ–¹ä¾¿é™¤éŒ¯ã€‚
    """
    import os

    # === å»ºç«‹ debug åœ–ç‰‡è³‡æ–™å¤¾ ===
    debug_dir = "debug_images"
    if save_debug and not os.path.exists(debug_dir):
        os.makedirs(debug_dir)

    # === 1. è®€å–åœ–ç‰‡ ===
    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°åœ–ç‰‡æª”æ¡ˆï¼š{image_path}")

    if save_debug:
        cv2.imwrite(os.path.join(debug_dir, "1_original.jpg"), img)

    # === 2. ç°éšåŒ– ===
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    if save_debug:
        cv2.imwrite(os.path.join(debug_dir, "2_gray.jpg"), gray)

    # === 3. å»é›œè¨Š ===
    blur = cv2.GaussianBlur(gray, (3, 3), 0)
    if save_debug:
        cv2.imwrite(os.path.join(debug_dir, "3_blur.jpg"), blur)

    # === 4. è‡ªé©æ‡‰é–¾å€¼äºŒå€¼åŒ– ===
    binary = cv2.adaptiveThreshold(
        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2
    )
    if save_debug:
        cv2.imwrite(os.path.join(debug_dir, "4_binary.jpg"), binary)

    # === 5. å»é™¤å°é›œé»ï¼ˆé–‹é‹ç®—ï¼‰ ===
    kernel = np.ones((1, 1), np.uint8)
    clean = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    if save_debug:
        cv2.imwrite(os.path.join(debug_dir, "5_clean.jpg"), clean)

    # === 6. å¯é¸ï¼šè‡ªå‹•åè½‰äº®åº¦ï¼ˆç™½åº•é»‘å­—è½‰é»‘åº•ç™½å­—ï¼‰ ===
    white_ratio = np.mean(clean > 127)
    if white_ratio > 0.5:  # è‹¥èƒŒæ™¯å¤ªäº®ï¼Œåè½‰é¡è‰²
        clean = cv2.bitwise_not(clean)
        if save_debug:
            cv2.imwrite(os.path.join(debug_dir, "6_inverted.jpg"), clean)

    return img


def extract_text(image_path: str, lang: str = "chi_tra+eng") -> str:
    """
    ä½¿ç”¨ Tesseract OCR é€²è¡Œåœ–ç‰‡æ–‡å­—è¾¨è­˜ã€‚
    é è¨­èªè¨€ç‚ºä¸­è‹±æ–‡æ··åˆã€‚
    """
    try:
        preprocessed = preprocess_image(image_path, save_debug=True)
        config = '--psm 6 --oem 3'
        print("[INFO] é–‹å§‹ OCR è¾¨è­˜...")
        text = pytesseract.image_to_string(preprocessed, lang=lang, config=config)
        print("[DEBUG OCR Raw Output]:", repr(text))
        cleaned = " ".join(text.split())
        return cleaned

    except Exception as e:
        print(f"[ERROR] OCR è¾¨è­˜å¤±æ•—ï¼š{e}")
        return ""


def extract_chat_lines(image_path: str) -> list:
    """
    å°‡ OCR æ–‡å­—åˆ‡å‰²æˆä¸€è¡Œä¸€è¡Œçš„å°è©±å½¢å¼
    ï¼ˆæ–¹ä¾¿å¾ŒçºŒå°è©±åˆ†ææ¨¡çµ„è™•ç†ï¼‰
    """
    text = extract_text(image_path)
    if not text:
        return []

    # æŒ‰å¥è™Ÿã€å•è™Ÿã€æ›è¡Œç¬¦æ‹†è§£
    lines = [
        line.strip()
        for line in text.replace("ã€‚", "\n").replace("?", "?\n").split("\n")
        if len(line.strip()) > 0
    ]
    return lines


if __name__ == "__main__":
    # æ¸¬è©¦ç¯„ä¾‹
    test_img = "example_chat.jpg"  # ä½ å¯ä»¥æ›æˆä½ çš„èŠå¤©æˆªåœ–
    if os.path.exists(test_img):
        print("ğŸ“· é–‹å§‹ OCR è¾¨è­˜...")
        lines = extract_chat_lines(test_img)
        print("\nè¾¨è­˜çµæœï¼š")
        for i, line in enumerate(lines, 1):
            print(f"{i}. {line}")
    else:
        print("âš ï¸ æ‰¾ä¸åˆ°æ¸¬è©¦åœ–ç‰‡ example_chat.png")
