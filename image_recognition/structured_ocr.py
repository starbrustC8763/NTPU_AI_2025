import io
import json
from google.cloud import vision
from typing import List, Dict
import os
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
def detect_chat_structure(image_path: str, threshold_ratio: float = 0.5) -> List[Dict]:
    """
    ä½¿ç”¨ Google Vision Document OCR åµæ¸¬èŠå¤©å…§å®¹ï¼Œä¸¦æ ¹æ“šæ–‡å­—ä½ç½®åˆ¤æ–·å·¦å³ç™¼è©±è€…ã€‚

    Args:
        image_path (str): åœ–ç‰‡è·¯å¾‘
        threshold_ratio (float): åˆ†ç•Œæ¯”ä¾‹ï¼ˆ0.5 è¡¨ç¤ºåœ–ç‰‡ä¸­ç·šï¼‰
    Returns:
        List[Dict]: åŒ…å«ç™¼è©±è€…èˆ‡æ–‡å­—çš„çµæ§‹åŒ–åˆ—è¡¨
    """
    client = vision.ImageAnnotatorClient()

    # è®€å–åœ–ç‰‡
    with io.open(image_path, 'rb') as image_file:
        content = image_file.read()
    image = vision.Image(content=content)

    # ä½¿ç”¨ document_text_detection å–å¾—å®Œæ•´ç‰ˆé¢è³‡è¨Š
    response = client.document_text_detection(image=image)

    if response.error.message:
        raise Exception(f"Vision API Error: {response.error.message}")

    results = []
    width = None

    # éæ­·æ¯ä¸€é ï¼ˆé€šå¸¸æ˜¯å–®å¼µï¼‰
    for page in response.full_text_annotation.pages:
        width = page.width or 1000
        for block in page.blocks:
            # çµ„åˆ block æ–‡å­—
            block_text = ""
            for paragraph in block.paragraphs:
                for word in paragraph.words:
                    word_text = ''.join([symbol.text for symbol in word.symbols])
                    block_text += word_text
                block_text += " "

            # åˆ¤æ–·æ°£æ³¡åœ¨å·¦æˆ–å³
            x_positions = [v.x for v in block.bounding_box.vertices]
            avg_x = sum(x_positions) / len(x_positions)
            #side = "left" if avg_x < width * threshold_ratio else "right"
            
            if avg_x < width * 0.6 and avg_x > width * 0.4:
                side = "middle"
            elif avg_x < width * threshold_ratio:
                side = "left"
            else:
                side = "right"
            # å–å¹³å‡ Y ä½ç½®ï¼ˆç”¨æ–¼æ’åºï¼‰
            avg_y = sum([v.y for v in block.bounding_box.vertices]) / len(block.bounding_box.vertices)

            results.append({
                "speaker": side,
                "text": block_text.strip(),
                "y_pos": avg_y
            })

    # ä¾ç…§å‚ç›´ä½ç½®æ’åº
    results.sort(key=lambda r: r["y_pos"])

    # ç§»é™¤ç©ºæ–‡å­—ã€åªä¿ç•™å¿…è¦æ¬„ä½
    structured_dialogue = [
        {"speaker": r["speaker"], "text": r["text"]}
        for r in results if r["text"]
    ]

    return structured_dialogue

def main():
    # æ¸¬è©¦ç¯„ä¾‹
    test_img = "piyan.png"  # ä½ å¯ä»¥æ›æˆä½ çš„èŠå¤©æˆªåœ–
    if os.path.exists(test_img):
        print("ğŸ“· é–‹å§‹ OCR è¾¨è­˜...")
        dialogues = detect_chat_structure(test_img)
        print("\n======================")
        print("ğŸ“œ çµæ§‹åŒ–è¾¨è­˜çµæœï¼š")
        print("======================")
        print(json.dumps(dialogues, ensure_ascii=False, indent=2))
    else:
        print(f"âš ï¸ æ‰¾ä¸åˆ°æ¸¬è©¦åœ–ç‰‡:{test_img}")
main()